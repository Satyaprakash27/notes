<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LangGraph: Advanced AI Agent Orchestration</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .header {
            background: rgba(255, 255, 255, 0.95);
            padding: 2rem;
            border-radius: 15px;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
            text-align: center;
        }

        .header h1 {
            color: #2c3e50;
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
            background: linear-gradient(45deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .header p {
            color: #666;
            font-size: 1.2rem;
        }

        .nav {
            background: rgba(255, 255, 255, 0.9);
            padding: 1rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            position: sticky;
            top: 20px;
            z-index: 100;
        }

        .nav ul {
            list-style: none;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 1rem;
        }

        .nav a {
            color: #667eea;
            text-decoration: none;
            padding: 0.5rem 1rem;
            border-radius: 25px;
            transition: all 0.3s ease;
            font-weight: 500;
        }

        .nav a:hover, .nav a.active {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }

        .content {
            background: rgba(255, 255, 255, 0.95);
            padding: 2rem;
            border-radius: 15px;
            margin-bottom: 2rem;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
            backdrop-filter: blur(10px);
        }

        .section {
            margin-bottom: 3rem;
        }

        h2 {
            color: #2c3e50;
            font-size: 2rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 3px solid #667eea;
            position: relative;
        }

        h3 {
            color: #34495e;
            font-size: 1.5rem;
            margin: 2rem 0 1rem 0;
            padding-left: 1rem;
            border-left: 4px solid #764ba2;
        }

        h4 {
            color: #555;
            font-size: 1.2rem;
            margin: 1.5rem 0 0.5rem 0;
        }

        .code-block {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 1.5rem;
            border-radius: 10px;
            margin: 1rem 0;
            overflow-x: auto;
            position: relative;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
        }

        .code-block pre {
            margin: 0;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.5;
        }

        .copy-btn {
            position: absolute;
            top: 10px;
            right: 10px;
            background: #667eea;
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 5px;
            cursor: pointer;
            font-size: 0.8rem;
            transition: all 0.3s ease;
        }

        .copy-btn:hover {
            background: #764ba2;
            transform: scale(1.05);
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5rem 0;
            background: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        .comparison-table th,
        .comparison-table td {
            padding: 1rem;
            text-align: left;
            border-bottom: 1px solid #eee;
        }

        .comparison-table th {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            font-weight: 600;
        }

        .comparison-table tr:hover {
            background: #f8f9ff;
        }

        .highlight-box {
            background: linear-gradient(135deg, #667eea20, #764ba220);
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 1.5rem;
            margin: 1.5rem 0;
        }

        .highlight-box h4 {
            color: #667eea;
            margin-top: 0;
        }

        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1.5rem;
            margin: 2rem 0;
        }

        .feature-card {
            background: white;
            padding: 1.5rem;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            border-left: 4px solid #667eea;
            transition: transform 0.3s ease;
        }

        .feature-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.15);
        }

        .feature-card h4 {
            color: #667eea;
            margin-bottom: 1rem;
        }

        .workflow-diagram {
            background: linear-gradient(135deg, #f8f9ff, #e8ecff);
            border: 2px solid #667eea;
            border-radius: 10px;
            padding: 2rem;
            margin: 2rem 0;
            text-align: center;
        }

        .workflow-step {
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 25px;
            margin: 0.5rem;
            font-weight: 500;
        }

        .workflow-arrow {
            font-size: 1.5rem;
            color: #764ba2;
            margin: 0 0.5rem;
        }

        .best-practice {
            background: #e8f5e8;
            border-left: 4px solid #27ae60;
            padding: 1rem 1.5rem;
            margin: 1rem 0;
            border-radius: 5px;
        }

        .best-practice:before {
            content: "✓ ";
            color: #27ae60;
            font-weight: bold;
            font-size: 1.2rem;
        }

        .warning {
            background: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 1rem 1.5rem;
            margin: 1rem 0;
            border-radius: 5px;
        }

        .warning:before {
            content: "⚠ ";
            color: #ffc107;
            font-weight: bold;
            font-size: 1.2rem;
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            
            .header h1 {
                font-size: 2rem;
            }
            
            .nav ul {
                flex-direction: column;
                align-items: center;
            }
            
            .code-block {
                font-size: 0.8rem;
            }
            
            .feature-grid {
                grid-template-columns: 1fr;
            }
        }

        /* Code syntax highlighting */
        .keyword { color: #569cd6; }
        .string { color: #ce9178; }
        .comment { color: #6a9955; }
        .function { color: #dcdcaa; }
        .class { color: #4ec9b0; }
        .number { color: #b5cea8; }
    </style>
</head>
<body>
    <div class="container">
        <header class="header">
            <h1>LangGraph: Advanced AI Agent Orchestration</h1>
            <p>Building stateful, multi-actor applications with Large Language Models</p>
        </header>

        <nav class="nav">
            <ul>
                <li><a href="#what-is-langgraph" class="nav-link">What is LangGraph?</a></li>
                <li><a href="#langgraph-vs-langchain" class="nav-link">vs LangChain</a></li>
                <li><a href="#use-cases" class="nav-link">Use Cases</a></li>
                <li><a href="#branching-logic" class="nav-link">Branching Logic</a></li>
                <li><a href="#advanced-examples" class="nav-link">Advanced Examples</a></li>
                <li><a href="#best-practices" class="nav-link">Best Practices</a></li>
            </ul>
        </nav>

        <main class="content">
            <section id="what-is-langgraph" class="section">
                <h2>What is LangGraph?</h2>
                
                <p>LangGraph is a library for building stateful, multi-actor applications with Large Language Models (LLMs). It extends LangChain's capabilities by providing a graph-based approach to orchestrating complex AI workflows.</p>

                <h3>Core Concepts</h3>
                
                <div class="feature-grid">
                    <div class="feature-card">
                        <h4>State Management</h4>
                        <p>Persistent state that flows through your entire workflow, enabling complex multi-step processes.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Graph-Based Workflow</h4>
                        <p>Nodes represent processing steps, edges represent transitions, enabling non-linear execution paths.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Conditional Routing</h4>
                        <p>Dynamic decision-making based on current state, allowing for intelligent workflow branching.</p>
                    </div>
                </div>

                <h4>1. State Management</h4>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>from typing import TypedDict, List
from langgraph.graph import StateGraph, END
from langchain_core.messages import HumanMessage, AIMessage

class AgentState(TypedDict):
    messages: List[HumanMessage | AIMessage]
    user_info: dict
    context: str
    next_action: str</code></pre>
                </div>

                <h4>2. Graph-Based Workflow</h4>
                <div class="highlight-box">
                    <h4>Unlike linear chains, LangGraph uses directed graphs where:</h4>
                    <ul>
                        <li><strong>Nodes</strong> represent processing steps (functions or agents)</li>
                        <li><strong>Edges</strong> represent transitions between steps</li>
                        <li><strong>Conditional edges</strong> enable dynamic routing based on state</li>
                    </ul>
                </div>

                <h4>3. Persistent State</h4>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code># State persists across the entire workflow
def analyze_input(state: AgentState):
    messages = state["messages"]
    # Process and update state
    return {
        "context": "User is asking about technical topic",
        "next_action": "research"
    }</code></pre>
                </div>

                <h3>Basic LangGraph Structure</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>from langgraph.graph import StateGraph, END

# Create a graph
workflow = StateGraph(AgentState)

# Add nodes (processing steps)
workflow.add_node("analyzer", analyze_input)
workflow.add_node("researcher", research_topic)
workflow.add_node("synthesizer", synthesize_response)

# Add edges (transitions)
workflow.add_edge("analyzer", "researcher")
workflow.add_conditional_edges(
    "researcher",
    should_continue_research,
    {
        "continue": "researcher",  # Loop back for more research
        "synthesize": "synthesizer",
        "end": END
    }
)

# Compile the graph
app = workflow.compile()</code></pre>
                </div>
            </section>

            <section id="langgraph-vs-langchain" class="section">
                <h2>LangGraph vs LangChain: Key Differences</h2>

                <h3>LangChain: Linear Sequential Processing</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code># Traditional LangChain approach
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# Linear chain - A → B → C
chain = (
    PromptTemplate.from_template("Analyze: {input}") |
    llm |
    PromptTemplate.from_template("Summarize: {text}") |
    llm
)

result = chain.invoke({"input": "What is quantum computing?"})</code></pre>
                </div>

                <h3>LangGraph: Graph-Based Dynamic Processing</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code># LangGraph approach - Dynamic routing and state management
def route_question(state: AgentState):
    question = state["messages"][-1].content
    
    if "technical" in question.lower():
        return "technical_expert"
    elif "creative" in question.lower():
        return "creative_expert"
    else:
        return "general_expert"

workflow.add_conditional_edges(
    "classifier",
    route_question,
    {
        "technical_expert": "technical_node",
        "creative_expert": "creative_node",
        "general_expert": "general_node"
    }
)</code></pre>
                </div>

                <h3>Key Advantages of LangGraph</h3>
                <table class="comparison-table">
                    <thead>
                        <tr>
                            <th>Feature</th>
                            <th>LangChain</th>
                            <th>LangGraph</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Workflow Type</strong></td>
                            <td>Linear/Sequential</td>
                            <td>Graph-based/Non-linear</td>
                        </tr>
                        <tr>
                            <td><strong>State Management</strong></td>
                            <td>Limited</td>
                            <td>Persistent across nodes</td>
                        </tr>
                        <tr>
                            <td><strong>Conditional Logic</strong></td>
                            <td>Basic</td>
                            <td>Advanced branching</td>
                        </tr>
                        <tr>
                            <td><strong>Loops & Cycles</strong></td>
                            <td>Not supported</td>
                            <td>Native support</td>
                        </tr>
                        <tr>
                            <td><strong>Multi-Agent</strong></td>
                            <td>Complex setup</td>
                            <td>Built-in support</td>
                        </tr>
                        <tr>
                            <td><strong>Debugging</strong></td>
                            <td>Limited visibility</td>
                            <td>Full state inspection</td>
                        </tr>
                        <tr>
                            <td><strong>Parallelization</strong></td>
                            <td>Manual</td>
                            <td>Automatic where possible</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <section id="use-cases" class="section">
                <h2>Use Cases for LangGraph</h2>

                <h3>1. Multi-Step Research Agents</h3>
                <p>LangGraph excels when you need agents that can research multiple sources, validate information, and iterate based on findings.</p>

                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>class ResearchState(TypedDict):
    query: str
    sources: List[str]
    findings: List[dict]
    confidence_score: float
    iterations: int

def research_agent():
    workflow = StateGraph(ResearchState)
    
    workflow.add_node("search", search_sources)
    workflow.add_node("validate", validate_findings)
    workflow.add_node("synthesize", synthesize_results)
    
    # Conditional logic based on confidence
    def should_continue_research(state):
        if state["confidence_score"] < 0.8 and state["iterations"] < 3:
            return "search"  # Continue researching
        return "synthesize"  # Move to synthesis
    
    workflow.add_conditional_edges(
        "validate",
        should_continue_research,
        {"search": "search", "synthesize": "synthesize"}
    )
    
    return workflow.compile()</code></pre>
                </div>

                <h3>2. Customer Support Workflows</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>class SupportState(TypedDict):
    customer_message: str
    intent: str
    sentiment: str
    escalation_level: int
    resolution_steps: List[str]

def customer_support_workflow():
    workflow = StateGraph(SupportState)
    
    # Classification step
    workflow.add_node("intent_classifier", classify_intent)
    workflow.add_node("sentiment_analyzer", analyze_sentiment)
    
    # Different handling paths
    workflow.add_node("technical_support", handle_technical)
    workflow.add_node("billing_support", handle_billing)
    workflow.add_node("escalation", escalate_to_human)
    
    # Routing logic
    def route_support(state):
        intent = state["intent"]
        sentiment = state["sentiment"]
        
        if sentiment == "very_negative":
            return "escalation"
        elif intent == "technical":
            return "technical_support"
        elif intent == "billing":
            return "billing_support"
        return "general_support"
    
    workflow.add_conditional_edges(
        "sentiment_analyzer",
        route_support,
        {
            "technical_support": "technical_support",
            "billing_support": "billing_support",
            "escalation": "escalation"
        }
    )
    
    return workflow.compile()</code></pre>
                </div>

                <h3>3. Content Generation with Feedback Loops</h3>
                <div class="workflow-diagram">
                    <span class="workflow-step">Outline</span>
                    <span class="workflow-arrow">→</span>
                    <span class="workflow-step">Write</span>
                    <span class="workflow-arrow">→</span>
                    <span class="workflow-step">Review</span>
                    <span class="workflow-arrow">↺</span>
                    <span class="workflow-step">Edit</span>
                    <span class="workflow-arrow">→</span>
                    <span class="workflow-step">Publish</span>
                </div>

                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>class ContentState(TypedDict):
    topic: str
    outline: str
    draft: str
    feedback: List[str]
    quality_score: float
    revision_count: int

def content_creation_workflow():
    workflow = StateGraph(ContentState)
    
    workflow.add_node("outliner", create_outline)
    workflow.add_node("writer", write_draft)
    workflow.add_node("reviewer", review_content)
    workflow.add_node("editor", edit_content)
    
    def should_revise(state):
        if state["quality_score"] < 0.7 and state["revision_count"] < 2:
            return "editor"  # Revise
        return END  # Publish
    
    workflow.add_conditional_edges(
        "reviewer",
        should_revise,
        {"editor": "editor", END: END}
    )
    
    # Editor can loop back to writer or reviewer
    workflow.add_conditional_edges(
        "editor",
        lambda state: "writer" if len(state["feedback"]) > 3 else "reviewer",
        {"writer": "writer", "reviewer": "reviewer"}
    )
    
    return workflow.compile()</code></pre>
                </div>
            </section>

            <section id="branching-logic" class="section">
                <h2>Implementing Branching Logic in LangGraph</h2>

                <h3>1. Simple Conditional Routing</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>from langgraph.graph import StateGraph, END

class SimpleState(TypedDict):
    user_input: str
    category: str
    confidence: float

def categorize_input(state: SimpleState):
    input_text = state["user_input"]
    # Simple categorization logic
    if "price" in input_text.lower() or "cost" in input_text.lower():
        return {"category": "pricing", "confidence": 0.9}
    elif "technical" in input_text.lower() or "how" in input_text.lower():
        return {"category": "technical", "confidence": 0.8}
    else:
        return {"category": "general", "confidence": 0.6}

def route_based_on_category(state: SimpleState):
    category = state["category"]
    confidence = state["confidence"]
    
    if confidence < 0.7:
        return "clarification_needed"
    elif category == "pricing":
        return "pricing_agent"
    elif category == "technical":
        return "technical_agent"
    else:
        return "general_agent"

# Build the workflow
workflow = StateGraph(SimpleState)
workflow.add_node("categorizer", categorize_input)
workflow.add_node("pricing_agent", handle_pricing_query)
workflow.add_node("technical_agent", handle_technical_query)
workflow.add_node("general_agent", handle_general_query)
workflow.add_node("clarifier", ask_for_clarification)

# Set entry point
workflow.set_entry_point("categorizer")

# Add conditional routing
workflow.add_conditional_edges(
    "categorizer",
    route_based_on_category,
    {
        "pricing_agent": "pricing_agent",
        "technical_agent": "technical_agent",
        "general_agent": "general_agent",
        "clarification_needed": "clarifier"
    }
)

# Handle clarification loop
workflow.add_conditional_edges(
    "clarifier",
    lambda state: "categorizer" if state.get("clarification_provided") else END,
    {"categorizer": "categorizer", END: END}
)

# All agents end the workflow
workflow.add_edge("pricing_agent", END)
workflow.add_edge("technical_agent", END)
workflow.add_edge("general_agent", END)

app = workflow.compile()</code></pre>
                </div>

                <h3>2. Complex Multi-Condition Branching</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>class ComplexState(TypedDict):
    user_profile: dict
    request_type: str
    priority: str
    complexity: str
    available_agents: List[str]
    current_load: dict

def intelligent_routing(state: ComplexState):
    user_profile = state["user_profile"]
    request_type = state["request_type"]
    priority = state["priority"]
    complexity = state["complexity"]
    current_load = state["current_load"]
    
    # Multi-factor decision making
    if user_profile.get("tier") == "premium" and priority == "high":
        if complexity == "high":
            return "senior_specialist"
        else:
            return "premium_support"
    
    elif request_type == "emergency":
        # Emergency routing regardless of other factors
        return "emergency_team"
    
    elif complexity == "high":
        # Route to specialist based on availability
        if current_load.get("specialist", 0) < 3:
            return "specialist"
        else:
            return "queue_for_specialist"
    
    else:
        # Standard routing with load balancing
        if current_load.get("general", 0) < current_load.get("technical", 0):
            return "general_support"
        else:
            return "technical_support"

# Advanced conditional edges with multiple outcomes
workflow.add_conditional_edges(
    "request_analyzer",
    intelligent_routing,
    {
        "senior_specialist": "senior_specialist_node",
        "premium_support": "premium_support_node",
        "emergency_team": "emergency_team_node",
        "specialist": "specialist_node",
        "queue_for_specialist": "specialist_queue_node",
        "general_support": "general_support_node",
        "technical_support": "technical_support_node"
    }
)</code></pre>
                </div>

                <h3>3. Dynamic Branching with External Data</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>import asyncio
from datetime import datetime

class DynamicState(TypedDict):
    request: str
    user_id: str
    timestamp: datetime
    external_data: dict
    routing_decision: str

async def fetch_external_context(state: DynamicState):
    user_id = state["user_id"]
    
    # Simulate external API calls
    user_history = await get_user_history(user_id)
    current_promotions = await get_active_promotions()
    system_status = await get_system_health()
    
    return {
        "external_data": {
            "user_history": user_history,
            "promotions": current_promotions,
            "system_status": system_status
        }
    }

def dynamic_router(state: DynamicState):
    external_data = state["external_data"]
    request = state["request"]
    
    # Dynamic routing based on real-time data
    if external_data["system_status"]["maintenance_mode"]:
        return "maintenance_handler"
    
    if "upgrade" in request and external_data["promotions"]:
        return "sales_specialist"
    
    if external_data["user_history"]["support_tickets"] > 5:
        return "priority_support"
    
    return "standard_support"

# Workflow with async external data fetching
workflow = StateGraph(DynamicState)
workflow.add_node("context_fetcher", fetch_external_context)
workflow.add_node("dynamic_router_node", lambda state: {"routing_decision": dynamic_router(state)})

# Multiple specialized handlers
workflow.add_node("maintenance_handler", handle_maintenance_request)
workflow.add_node("sales_specialist", handle_sales_inquiry)
workflow.add_node("priority_support", handle_priority_request)
workflow.add_node("standard_support", handle_standard_request)

workflow.set_entry_point("context_fetcher")
workflow.add_edge("context_fetcher", "dynamic_router_node")

workflow.add_conditional_edges(
    "dynamic_router_node",
    lambda state: state["routing_decision"],
    {
        "maintenance_handler": "maintenance_handler",
        "sales_specialist": "sales_specialist",
        "priority_support": "priority_support",
        "standard_support": "standard_support"
    }
)</code></pre>
                </div>
            </section>

            <section id="advanced-examples" class="section">
                <h2>Advanced Examples</h2>

                <h3>1. Multi-Agent Collaboration</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>class CollaborationState(TypedDict):
    task: str
    research_results: List[dict]
    analysis_results: List[dict]
    synthesis_result: str
    quality_check: bool
    iteration_count: int

def research_agent(state: CollaborationState):
    task = state["task"]
    # Perform research
    results = perform_research(task)
    return {"research_results": results}

def analysis_agent(state: CollaborationState):
    research_results = state["research_results"]
    # Analyze research findings
    analysis = analyze_findings(research_results)
    return {"analysis_results": analysis}

def synthesis_agent(state: CollaborationState):
    research_results = state["research_results"]
    analysis_results = state["analysis_results"]
    # Synthesize final result
    synthesis = synthesize_information(research_results, analysis_results)
    return {"synthesis_result": synthesis}

def quality_checker(state: CollaborationState):
    synthesis_result = state["synthesis_result"]
    # Check quality
    quality_score = check_quality(synthesis_result)
    return {"quality_check": quality_score > 0.8}

def should_iterate(state: CollaborationState):
    if not state["quality_check"] and state["iteration_count"] < 3:
        return "research_agent"  # Start over
    return END

# Multi-agent workflow
workflow = StateGraph(CollaborationState)
workflow.add_node("research_agent", research_agent)
workflow.add_node("analysis_agent", analysis_agent)
workflow.add_node("synthesis_agent", synthesis_agent)
workflow.add_node("quality_checker", quality_checker)

workflow.set_entry_point("research_agent")
workflow.add_edge("research_agent", "analysis_agent")
workflow.add_edge("analysis_agent", "synthesis_agent")
workflow.add_edge("synthesis_agent", "quality_checker")

workflow.add_conditional_edges(
    "quality_checker",
    should_iterate,
    {"research_agent": "research_agent", END: END}
)

multi_agent_app = workflow.compile()</code></pre>
                </div>

                <h3>2. Human-in-the-Loop Workflow</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>class HumanLoopState(TypedDict):
    initial_request: str
    ai_response: str
    human_feedback: str
    approval_status: str
    final_output: str

def generate_initial_response(state: HumanLoopState):
    request = state["initial_request"]
    response = llm.invoke(f"Generate response for: {request}")
    return {"ai_response": response}

def wait_for_human_feedback(state: HumanLoopState):
    # This would integrate with a UI or messaging system
    print(f"AI Response: {state['ai_response']}")
    feedback = input("Please provide feedback (approve/revise/reject): ")
    return {"human_feedback": feedback}

def process_feedback(state: HumanLoopState):
    feedback = state["human_feedback"]
    
    if feedback.lower() == "approve":
        return {"approval_status": "approved"}
    elif feedback.lower() == "revise":
        return {"approval_status": "revise"}
    else:
        return {"approval_status": "rejected"}

def revise_response(state: HumanLoopState):
    original_response = state["ai_response"]
    feedback = state["human_feedback"]
    
    revised = llm.invoke(f"Revise this response based on feedback:\n"
                        f"Original: {original_response}\n"
                        f"Feedback: {feedback}")
    return {"ai_response": revised}

def finalize_output(state: HumanLoopState):
    return {"final_output": state["ai_response"]}

# Human-in-the-loop workflow
workflow = StateGraph(HumanLoopState)
workflow.add_node("generate", generate_initial_response)
workflow.add_node("human_review", wait_for_human_feedback)
workflow.add_node("process_feedback", process_feedback)
workflow.add_node("revise", revise_response)
workflow.add_node("finalize", finalize_output)

workflow.set_entry_point("generate")
workflow.add_edge("generate", "human_review")
workflow.add_edge("human_review", "process_feedback")

def route_after_feedback(state: HumanLoopState):
    status = state["approval_status"]
    if status == "approved":
        return "finalize"
    elif status == "revise":
        return "revise"
    else:  # rejected
        return END

workflow.add_conditional_edges(
    "process_feedback",
    route_after_feedback,
    {
        "finalize": "finalize",
        "revise": "revise",
        END: END
    }
)

# After revision, go back for human review
workflow.add_edge("revise", "human_review")
workflow.add_edge("finalize", END)

human_loop_app = workflow.compile()</code></pre>
                </div>
            </section>

            <section id="best-practices" class="section">
                <h2>Best Practices</h2>

                <h3>1. State Design</h3>
                <div class="best-practice">
                    Use well-structured state with clear types and meaningful field names
                </div>

                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code># Good: Well-structured state with clear types
class WellDesignedState(TypedDict):
    # Core data
    user_input: str
    session_id: str
    
    # Processing state
    current_step: str
    step_history: List[str]
    
    # Results
    intermediate_results: dict
    final_result: str
    
    # Metadata
    timestamp: datetime
    processing_time: float
    error_count: int

# Avoid: Flat, unstructured state
class PoorState(TypedDict):
    data: dict  # Too generic
    stuff: str  # Unclear purpose
    temp: any   # Unknown type</code></pre>
                </div>

                <h3>2. Error Handling</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code>def safe_node_execution(func):
    def wrapper(state):
        try:
            result = func(state)
            return {**result, "error_count": state.get("error_count", 0)}
        except Exception as e:
            error_count = state.get("error_count", 0) + 1
            return {
                "error_count": error_count,
                "last_error": str(e),
                "failed_step": func.__name__
            }
    return wrapper

@safe_node_execution
def risky_operation(state: AgentState):
    # Operation that might fail
    result = external_api_call(state["input"])
    return {"result": result}

def error_handler(state: AgentState):
    if state["error_count"] > 3:
        return "escalate_to_human"
    elif state["error_count"] > 0:
        return "retry_with_fallback"
    else:
        return "continue_normal_flow"</code></pre>
                </div>

                <h3>3. Performance Optimization</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code># Use checkpoints for long-running workflows
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
app = workflow.compile(checkpointer=memory)

# This allows resuming from any point
config = {"configurable": {"thread_id": "user-123"}}
result = app.invoke(initial_state, config=config)

# Parallel execution where possible
def parallel_research(state: ResearchState):
    import asyncio
    
    async def parallel_search():
        tasks = [
            search_source_1(state["query"]),
            search_source_2(state["query"]),
            search_source_3(state["query"])
        ]
        results = await asyncio.gather(*tasks)
        return {"research_results": results}
    
    return asyncio.run(parallel_search())</code></pre>
                </div>

                <div class="highlight-box">
                    <h4>Key Performance Tips</h4>
                    <ul>
                        <li><strong>Keep state lean:</strong> Remove unnecessary data between steps</li>
                        <li><strong>Cache expensive operations:</strong> Store results in state when possible</li>
                        <li><strong>Use streaming:</strong> For large datasets, process in chunks</li>
                        <li><strong>Implement checkpoints:</strong> Allow resuming long-running workflows</li>
                        <li><strong>Monitor state size:</strong> Large states can impact performance</li>
                    </ul>
                </div>

                <h3>Memory Usage Optimization</h3>
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode(this)">Copy</button>
                    <pre><code># Use streaming for large datasets
def streaming_processor(state: LargeDataState):
    results = []
    for chunk in stream_large_dataset(state["data_source"]):
        processed_chunk = process_chunk(chunk)
        results.append(processed_chunk)
        
        # Clear processed data to save memory
        del chunk
    
    return {"processed_results": results}</code></pre>
                </div>

                <div class="warning">
                    Avoid expensive operations in routing functions as they're called frequently during workflow execution.
                </div>
            </section>
        </main>
    </div>

    <script>
        // Copy code functionality
        function copyCode(button) {
            const codeBlock = button.nextElementSibling.textContent;
            navigator.clipboard.writeText(codeBlock).then(() => {
                const originalText = button.textContent;
                button.textContent = 'Copied!';
                button.style.background = '#27ae60';
                setTimeout(() => {
                    button.textContent = originalText;
                    button.style.background = '#667eea';
                }, 2000);
            });
        }

        // Smooth scrolling for navigation
        document.querySelectorAll('.nav-link').forEach(link => {
            link.addEventListener('click', (e) => {
                e.preventDefault();
                const targetId = link.getAttribute('href').substring(1);
                const targetElement = document.getElementById(targetId);
                
                if (targetElement) {
                    targetElement.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
                
                // Update active link
                document.querySelectorAll('.nav-link').forEach(l => l.classList.remove('active'));
                link.classList.add('active');
            });
        });

        // Update active navigation on scroll
        window.addEventListener('scroll', () => {
            const sections = document.querySelectorAll('.section');
            const navLinks = document.querySelectorAll('.nav-link');
            
            let current = '';
            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                const sectionHeight = section.clientHeight;
                if (window.pageYOffset >= sectionTop - 200) {
                    current = section.getAttribute('id');
                }
            });
            
            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href').substring(1) === current) {
                    link.classList.add('active');
                }
            });
        });

        // Add fade-in animation to sections
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        }, observerOptions);

        document.querySelectorAll('.section').forEach(section => {
            section.style.opacity = '0';
            section.style.transform = 'translateY(20px)';
            section.style.transition = 'opacity 0.6s ease, transform 0.6s ease';
            observer.observe(section);
        });
    </script>
</body>
</html>
