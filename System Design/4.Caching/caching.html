<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üóÑÔ∏è Caching in System Design Guide</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #e8e8e8;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            min-height: 100vh;
            margin: 0;
            display: flex;
        }

        .sidebar {
            width: 280px;
            background: #1e1e1e;
            color: white;
            height: 100vh;
            position: fixed;
            left: 0;
            top: 0;
            overflow-y: auto;
            z-index: 1000;
            transition: transform 0.3s ease;
            border-right: 1px solid #333;
        }

        .sidebar-header {
            padding: 20px;
            background: #2d2d2d;
            border-bottom: 1px solid #444;
        }

        .sidebar-header h2 {
            margin: 0;
            font-size: 1.3em;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            color: #f0f0f0;
            border: none;
            padding: 0;
        }

        .sidebar-nav {
            padding: 0;
        }

        .sidebar-link {
            display: block;
            color: #b8b8b8;
            text-decoration: none;
            padding: 15px 20px;
            border-bottom: 1px solid #444;
            transition: background 0.2s ease;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            font-size: 1.1em;
            font-weight: 500;
        }

        .sidebar-link:hover {
            background: #3a3a3a;
            color: #f0f0f0;
        }

        .sidebar-link.current {
            background: #3498db;
            color: white;
            font-weight: 600;
        }

        .sidebar-toggle {
            display: none;
            position: fixed;
            top: 20px;
            left: 20px;
            z-index: 1001;
            background: #3498db;
            color: white;
            border: none;
            padding: 10px;
            border-radius: 5px;
            cursor: pointer;
        }

        .main-content {
            margin-left: 280px;
            flex: 1;
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: rgba(30, 30, 30, 0.95);
            backdrop-filter: blur(10px);
            padding: 30px;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3);
            border: 1px solid #444;
        }

        h1 {
            color: #f0f0f0;
            text-align: center;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            font-size: 2.5em;
            margin-bottom: 30px;
        }

        h2 {
            color: #e0e0e0;
            border-left: 4px solid #3498db;
            padding-left: 15px;
            margin-top: 30px;
            font-size: 1.8em;
        }

        h3 {
            color: #3498db;
            margin-top: 25px;
            font-size: 1.4em;
        }

        h4 {
            color: #5dade2;
            margin-top: 20px;
            font-size: 1.2em;
        }

        h5 {
            color: #85c1e9;
            margin-top: 15px;
            font-size: 1.1em;
        }

        .toc {
            background: rgba(52, 152, 219, 0.15);
            padding: 1rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
            position: sticky;
            top: 20px;
            z-index: 100;
            backdrop-filter: blur(10px);
            border: 2px solid rgba(52, 152, 219, 0.3);
        }

        .toc ul {
            list-style-type: none;
            padding-left: 0;
            margin: 0;
            display: flex;
            flex-wrap: wrap;
            justify-content: space-evenly;
            align-items: center;
            gap: 0.5rem;
        }

        .toc li {
            margin: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            flex: 0 1 calc(25% - 0.5rem);
            min-width: 120px;
        }

        .toc a {
            color: #e0e0e0;
            text-decoration: none;
            padding: 0.5rem 1rem;
            border-radius: 25px;
            transition: all 0.3s ease;
            font-weight: 600;
            font-size: 0.8em;
            display: flex;
            align-items: center;
            justify-content: center;
            text-align: center;
            white-space: nowrap;
            background: rgba(50, 50, 50, 0.7);
            border: 1px solid rgba(52, 152, 219, 0.3);
            min-height: 40px;
            width: 100%;
        }

        .toc a:hover, .toc a.active {
            background: linear-gradient(45deg, #3498db, #5dade2);
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(52, 152, 219, 0.4);
        }

        pre {
            background: #000000;
            color: #ffffff;
            padding: 20px;
            border-radius: 10px;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            margin: 15px 0;
        }

        code {
            background: #000000;
            padding: 3px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            color: #ffffff;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: #2a2a2a;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            border-radius: 10px;
            overflow: hidden;
        }

        th, td {
            border: 1px solid #444;
            padding: 12px;
            text-align: left;
            color: #e0e0e0;
        }

        th {
            background: #3498db;
            color: white;
            font-weight: bold;
        }

        tr:nth-child(even) {
            background: #333;
        }

        tr:hover {
            background: #404040;
        }

        .overview {
            background: #2a2a3a;
            border: 1px solid #3498db;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #e0e0f0;
        }

        .cache-strategy {
            background: #1a3a2a;
            border: 1px solid #27ae60;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #90ee90;
        }

        .eviction-policy {
            background: #3a2a1a;
            border: 1px solid #f39c12;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #ffc966;
        }

        .redis-section {
            background: #2a1a3a;
            border: 1px solid #9b59b6;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #d1a3ff;
        }

        .memcached-section {
            background: #1a2a3a;
            border: 1px solid #3498db;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #a8c8f0;
        }

        .cdn-section {
            background: #3a1a1a;
            border: 1px solid #e74c3c;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #ffb3b3;
        }

        .best-practices {
            background: #2a3a1a;
            border: 1px solid #f1c40f;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #f4d03f;
        }

        .example {
            background: #2a2a2a;
            border-left: 4px solid #17a2b8;
            padding: 20px;
            margin: 20px 0;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #e0e0e0;
        }

        .example h5 {
            margin-top: 0;
            color: #17a2b8;
            font-size: 1.1em;
        }

        .benefits {
            background: #1a3a1a;
            border: 1px solid #3498db;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #90ee90;
        }

        .benefits ul {
            margin: 10px 0;
        }

        .benefits li {
            margin: 5px 0;
        }

        .warning {
            background: #3a2f1a;
            border: 1px solid #b8860b;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #ffd700;
        }

        .warning::before {
            content: "‚ö†Ô∏è ";
            font-weight: bold;
            font-size: 1.2em;
        }

        .tip {
            background: #1a3a2f;
            border: 1px solid #27ae60;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.3);
            color: #7bed9f;
        }

        .tip::before {
            content: "üí° ";
            font-weight: bold;
            font-size: 1.2em;
        }

        @media (max-width: 1024px) {
            .toc ul {
                justify-content: center;
                gap: 0.75rem;
            }
        }

        @media (max-width: 768px) {
            .sidebar {
                transform: translateX(-100%);
            }

            .sidebar.active {
                transform: translateX(0);
            }

            .sidebar-toggle {
                display: block;
            }

            .main-content {
                margin-left: 0;
                padding: 15px;
            }

            .container {
                padding: 20px;
            }

            h1 {
                font-size: 2em;
            }

            h2 {
                font-size: 1.5em;
            }

            table {
                font-size: 0.9em;
            }

            .toc {
                position: static;
                margin: 20px 0;
            }

            .toc ul {
                flex-direction: column;
                align-items: stretch;
                gap: 0.3rem;
            }

            .toc li {
                flex: 1;
                min-width: auto;
            }
        }
    </style>
</head>
<body>
    <button class="sidebar-toggle" onclick="toggleSidebar()">‚ò∞</button>
    
    <div class="sidebar" id="sidebar">
        <div class="sidebar-header">
            <h2><a href="../" style="color: inherit; text-decoration: none;">üóÇÔ∏è System Design</a></h2>
        </div>
        <nav class="sidebar-nav">
            <a href="../1.Fundamentals/system-design-fundamentals.html" class="sidebar-link">
                üèóÔ∏è Fundamentals
            </a>
            <a href="../2.Networking & Communication/networking-communication.html" class="sidebar-link">
                üåê Networking & Communication
            </a>
            <a href="../3.Databases/databases.html" class="sidebar-link">
                üóÉÔ∏è Databases
            </a>
            <a href="../4.Caching/caching.html" class="sidebar-link current">
                üóÑÔ∏è Caching
            </a>
            <a href="../5.Message Queues & Event-Driven Systems/message-queues-event-driven.html" class="sidebar-link">
                üì¨ Message Queues & Events
            </a>
            <a href="../6.Storage Systems/storage-systems.html" class="sidebar-link">
                üíæ Storage Systems
            </a>
            <a href="../7.Design Patterns & Architecture/design-patterns-architecture.html" class="sidebar-link">
                üèõÔ∏è Design Patterns
            </a>
            <a href="../8.Scalability & Performance/scalability-performance.html" class="sidebar-link">
                üìà Scalability & Performance
            </a>
            <a href="../9.Security in System Design/security-system-design.html" class="sidebar-link">
                üîí Security
            </a>
            <a href="../10.Monitoring & Observability/monitoring-observability.html" class="sidebar-link">
                üìä Monitoring & Observability
            </a>
            <a href="../11.Deployment & DevOps/deployment-devops.html" class="sidebar-link">
                üöÄ Deployment & DevOps
            </a>
            <a href="../12.Popular Use Cases/popular-use-cases.html" class="sidebar-link">
                üéØ Popular Use Cases
            </a>
            <a href="../13.Trade-offs & Decision Making/trade-offs-decision-making.html" class="sidebar-link">
                ‚öñÔ∏è Trade-offs & Decisions
            </a>
        </nav>
    </div>

    <div class="main-content">
        <div class="container">
            <h1>üóÑÔ∏è Caching in System Design</h1>
            
            <div class="toc" id="toc">
                <ul>
                    <li><a href="#overview">Overview</a></li>
                    <li><a href="#strategies">Cache Strategies</a></li>
                    <li><a href="#eviction">Eviction Policies</a></li>
                    <li><a href="#redis-memcached">Redis & Memcached</a></li>
                    <li><a href="#cdn">CDN Caching</a></li>
                    <li><a href="#best-practices">Best Practices</a></li>
                    <li><a href="#pitfalls">Common Pitfalls</a></li>
                    <li><a href="#summary">Summary</a></li>
                </ul>
            </div>

            <h2 id="overview">Overview</h2>
            <div class="overview">
                <p>Caching is one of the most fundamental techniques in system design for improving performance, reducing latency, and decreasing load on backend systems. A cache is a high-speed storage layer that stores frequently accessed data in memory, allowing applications to retrieve information much faster than fetching it from the original data source.</p>
                
                <p>Effective caching strategies can dramatically improve system performance, user experience, and resource utilization. This comprehensive guide covers the essential caching concepts, strategies, and technologies used in modern system design.</p>
            </div>

            <h2 id="strategies">üîÑ Caching Strategies</h2>
            <p>Caching strategies determine when and how data is written to and read from the cache. The choice of strategy impacts performance, consistency, and system complexity.</p>

            <h3>Write-Through Cache</h3>
            <div class="cache-strategy">
                <p><strong>Write-Through</strong> is a caching strategy where data is written to both the cache and the backing store simultaneously.</p>
                
                <h4>How It Works:</h4>
                <ul>
                    <li><strong>Write Operation:</strong> Data is written to the cache first</li>
                    <li><strong>Immediate Write:</strong> The same data is immediately written to the persistent storage</li>
                    <li><strong>Confirmation:</strong> Operation completes only after both writes succeed</li>
                </ul>
            </div>

            <div class="example">
                <h5>Write-Through Implementation:</h5>
                <pre><code>class WriteThroughCache:
    def __init__(self, cache, database):
        self.cache = cache
        self.database = database
    
    def write(self, key, value):
        # Write to cache first
        self.cache.set(key, value)
        
        # Immediately write to database
        self.database.save(key, value)
        
        return True
    
    def read(self, key):
        # Try cache first
        value = self.cache.get(key)
        if value is not None:
            return value
        
        # Fallback to database
        value = self.database.get(key)
        if value is not None:
            self.cache.set(key, value)
        
        return value</code></pre>
            </div>

            <div class="benefits">
                <h4>Advantages:</h4>
                <ul>
                    <li><strong>Data Consistency:</strong> Cache and database are always in sync</li>
                    <li><strong>Data Reliability:</strong> No risk of data loss since data is immediately persisted</li>
                    <li><strong>Read Performance:</strong> Subsequent reads are served from fast cache</li>
                    <li><strong>Fault Tolerance:</strong> If cache fails, data is still available in persistent storage</li>
                </ul>
            </div>

            <div class="warning">
                <h4>Disadvantages:</h4>
                <ul>
                    <li><strong>Write Latency:</strong> Higher write latency due to dual writes</li>
                    <li><strong>Write Throughput:</strong> Lower write performance compared to write-back</li>
                    <li><strong>Resource Usage:</strong> Requires both cache and database writes for every operation</li>
                </ul>
            </div>

            <h3>Write-Around Cache</h3>
            <div class="cache-strategy">
                <p><strong>Write-Around</strong> is a caching strategy where data is written directly to the backing store, bypassing the cache.</p>
                
                <h4>How It Works:</h4>
                <ul>
                    <li><strong>Write Operation:</strong> Data is written directly to persistent storage</li>
                    <li><strong>Cache Bypass:</strong> Cache is not updated during write operations</li>
                    <li><strong>Lazy Loading:</strong> Data is loaded into cache only when read</li>
                </ul>
            </div>

            <div class="example">
                <h5>Write-Around Implementation:</h5>
                <pre><code>class WriteAroundCache:
    def __init__(self, cache, database):
        self.cache = cache
        self.database = database
    
    def write(self, key, value):
        # Write directly to database, bypass cache
        self.database.save(key, value)
        
        # Optionally invalidate cache entry
        self.cache.delete(key)
        
        return True
    
    def read(self, key):
        # Try cache first
        value = self.cache.get(key)
        if value is not None:
            return value
        
        # Load from database and cache
        value = self.database.get(key)
        if value is not None:
            self.cache.set(key, value)
        
        return value</code></pre>
            </div>

            <h3>Write-Back Cache (Write-Behind)</h3>
            <div class="cache-strategy">
                <p><strong>Write-Back</strong> is a caching strategy where data is written to the cache immediately, but the write to the backing store is deferred.</p>
                
                <h4>How It Works:</h4>
                <ul>
                    <li><strong>Write Operation:</strong> Data is written to cache immediately</li>
                    <li><strong>Deferred Write:</strong> Write to persistent storage is scheduled for later</li>
                    <li><strong>Batch Processing:</strong> Multiple writes may be batched together</li>
                    <li><strong>Asynchronous Sync:</strong> Cache and database are synchronized asynchronously</li>
                </ul>
            </div>

            <div class="example">
                <h5>Write-Back Implementation:</h5>
                <pre><code>import asyncio
from collections import defaultdict

class WriteBackCache:
    def __init__(self, cache, database, sync_interval=5):
        self.cache = cache
        self.database = database
        self.dirty_keys = set()
        self.sync_interval = sync_interval
        self.start_sync_task()
    
    def write(self, key, value):
        # Write to cache immediately
        self.cache.set(key, value)
        
        # Mark as dirty for later sync
        self.dirty_keys.add(key)
        
        return True
    
    def read(self, key):
        # Always read from cache first
        value = self.cache.get(key)
        if value is not None:
            return value
        
        # Load from database if not in cache
        value = self.database.get(key)
        if value is not None:
            self.cache.set(key, value)
        
        return value
    
    async def sync_to_database(self):
        while True:
            await asyncio.sleep(self.sync_interval)
            
            # Get dirty keys to sync
            keys_to_sync = list(self.dirty_keys)
            self.dirty_keys.clear()
            
            # Sync to database
            for key in keys_to_sync:
                value = self.cache.get(key)
                if value is not None:
                    self.database.save(key, value)</code></pre>
            </div>

            <h3>Strategy Comparison</h3>
            <table>
                <tr>
                    <th>Strategy</th>
                    <th>Write Performance</th>
                    <th>Read Performance</th>
                    <th>Consistency</th>
                    <th>Complexity</th>
                    <th>Data Safety</th>
                </tr>
                <tr><td><strong>Write-Through</strong></td><td>Slow</td><td>Fast</td><td>Strong</td><td>Low</td><td>High</td></tr>
                <tr><td><strong>Write-Around</strong></td><td>Fast</td><td>Variable</td><td>Eventual</td><td>Low</td><td>High</td></tr>
                <tr><td><strong>Write-Back</strong></td><td>Very Fast</td><td>Fast</td><td>Eventual</td><td>High</td><td>Medium</td></tr>
            </table>

            <h2 id="eviction">üóëÔ∏è Cache Eviction Policies</h2>
            <p>Cache eviction policies determine which data should be removed from the cache when it reaches capacity. The choice of eviction policy significantly impacts cache performance and hit rates.</p>

            <h3>Least Recently Used (LRU)</h3>
            <div class="eviction-policy">
                <p><strong>LRU</strong> evicts the least recently accessed items first, based on the principle that recently accessed data is more likely to be accessed again.</p>
                
                <h4>How It Works:</h4>
                <ul>
                    <li><strong>Access Tracking:</strong> Maintains access timestamps or access order</li>
                    <li><strong>Eviction Decision:</strong> Removes items that haven't been accessed for the longest time</li>
                    <li><strong>Update on Access:</strong> Updates access information on every read/write</li>
                </ul>
            </div>

            <div class="example">
                <h5>LRU Cache Implementation:</h5>
                <pre><code>from collections import OrderedDict

class LRUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = OrderedDict()
    
    def get(self, key):
        if key in self.cache:
            # Move to end (most recently used)
            self.cache.move_to_end(key)
            return self.cache[key]
        return None
    
    def set(self, key, value):
        if key in self.cache:
            # Update existing key
            self.cache[key] = value
            self.cache.move_to_end(key)
        else:
            # Add new key
            if len(self.cache) >= self.capacity:
                # Remove least recently used (first item)
                self.cache.popitem(last=False)
            self.cache[key] = value</code></pre>
            </div>

            <h3>Least Frequently Used (LFU)</h3>
            <div class="eviction-policy">
                <p><strong>LFU</strong> evicts the least frequently accessed items first, based on the principle that frequently accessed data is more likely to be accessed again.</p>
                
                <h4>How It Works:</h4>
                <ul>
                    <li><strong>Frequency Tracking:</strong> Maintains access frequency counters</li>
                    <li><strong>Eviction Decision:</strong> Removes items with lowest access frequency</li>
                    <li><strong>Counter Updates:</strong> Increments frequency on every access</li>
                </ul>
            </div>

            <div class="example">
                <h5>LFU Cache Implementation:</h5>
                <pre><code>from collections import defaultdict

class LFUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = {}
        self.frequencies = defaultdict(int)
        self.min_frequency = 0
        self.frequency_groups = defaultdict(set)
    
    def get(self, key):
        if key not in self.cache:
            return None
        
        # Update frequency
        self._update_frequency(key)
        return self.cache[key]
    
    def set(self, key, value):
        if self.capacity <= 0:
            return
        
        if key in self.cache:
            # Update existing key
            self.cache[key] = value
            self._update_frequency(key)
        else:
            # Add new key
            if len(self.cache) >= self.capacity:
                self._evict_lfu()
            
            self.cache[key] = value
            self.frequencies[key] = 1
            self.frequency_groups[1].add(key)
            self.min_frequency = 1
    
    def _update_frequency(self, key):
        old_freq = self.frequencies[key]
        new_freq = old_freq + 1
        
        # Remove from old frequency group
        self.frequency_groups[old_freq].remove(key)
        
        # Update frequency
        self.frequencies[key] = new_freq
        self.frequency_groups[new_freq].add(key)
        
        # Update min frequency if necessary
        if old_freq == self.min_frequency and not self.frequency_groups[old_freq]:
            self.min_frequency += 1</code></pre>
            </div>

            <h3>First In, First Out (FIFO)</h3>
            <div class="eviction-policy">
                <p><strong>FIFO</strong> evicts the oldest items first, regardless of access patterns, following a simple queue-like behavior.</p>
                
                <h4>Characteristics:</h4>
                <ul>
                    <li><strong>Simple Implementation:</strong> Easy to implement and understand</li>
                    <li><strong>Low Overhead:</strong> Minimal memory overhead for tracking</li>
                    <li><strong>Predictable:</strong> Deterministic eviction behavior</li>
                    <li><strong>Ignores Access Patterns:</strong> Doesn't consider frequency or recency</li>
                </ul>
            </div>

            <div class="example">
                <h5>FIFO Cache Implementation:</h5>
                <pre><code>from collections import deque

class FIFOCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = {}
        self.order = deque()
    
    def get(self, key):
        return self.cache.get(key)
    
    def set(self, key, value):
        if key in self.cache:
            # Update existing key (don't change order)
            self.cache[key] = value
        else:
            # Add new key
            if len(self.cache) >= self.capacity:
                # Remove oldest item
                oldest_key = self.order.popleft()
                del self.cache[oldest_key]
            
            self.cache[key] = value
            self.order.append(key)</code></pre>
            </div>

            <h3>Eviction Policy Comparison</h3>
            <table>
                <tr>
                    <th>Policy</th>
                    <th>Implementation</th>
                    <th>Overhead</th>
                    <th>Performance</th>
                    <th>Use Case</th>
                </tr>
                <tr><td><strong>LRU</strong></td><td>Medium</td><td>Medium</td><td>Good</td><td>General purpose</td></tr>
                <tr><td><strong>LFU</strong></td><td>Complex</td><td>High</td><td>Excellent</td><td>Skewed access patterns</td></tr>
                <tr><td><strong>FIFO</strong></td><td>Simple</td><td>Low</td><td>Poor</td><td>Simple scenarios</td></tr>
                <tr><td><strong>Random</strong></td><td>Simple</td><td>Low</td><td>Unpredictable</td><td>Testing, simple systems</td></tr>
            </table>

            <h2 id="redis-memcached">üîß Redis and Memcached</h2>
            <p>Redis and Memcached are two of the most popular in-memory caching solutions, each with distinct characteristics and use cases.</p>

            <h3>Redis</h3>
            <div class="redis-section">
                <p><strong>Redis</strong> (Remote Dictionary Server) is an in-memory data structure store that can be used as a cache, database, and message broker.</p>
                
                <h4>Key Features:</h4>
                <ul>
                    <li><strong>Rich Data Structures:</strong> Strings, lists, sets, sorted sets, hashes, bitmaps</li>
                    <li><strong>Persistence:</strong> Optional disk persistence with RDB snapshots and AOF logging</li>
                    <li><strong>Replication:</strong> Master-slave replication for high availability</li>
                    <li><strong>Clustering:</strong> Built-in clustering support for horizontal scaling</li>
                    <li><strong>Pub/Sub:</strong> Built-in publish/subscribe messaging</li>
                </ul>
            </div>

            <h4>Redis Data Structures</h4>
            <div class="example">
                <h5>Redis Operations:</h5>
                <pre><code># Strings
SET user:1001 "John Doe"
GET user:1001
INCR page_views
EXPIRE user:1001 3600

# Lists (queues, stacks)
LPUSH tasks "task1" "task2"
RPOP tasks
LRANGE tasks 0 -1

# Sets (unique items)
SADD users:online "user1" "user2"
SISMEMBER users:online "user1"
SUNION users:online users:premium

# Sorted Sets (leaderboards)
ZADD leaderboard 1500 "player1" 1200 "player2"
ZRANGE leaderboard 0 -1 WITHSCORES

# Hashes (objects)
HSET user:1001 name "John" email "john@example.com"
HGETALL user:1001</code></pre>
            </div>

            <div class="example">
                <h5>Redis Python Implementation:</h5>
                <pre><code>import redis
import json

class RedisCache:
    def __init__(self, host='localhost', port=6379, db=0):
        self.client = redis.Redis(
            host=host,
            port=port,
            db=db,
            decode_responses=True
        )
    
    def set(self, key, value, ttl=None):
        """Set a key-value pair with optional TTL"""
        serialized_value = json.dumps(value)
        if ttl:
            return self.client.setex(key, ttl, serialized_value)
        else:
            return self.client.set(key, serialized_value)
    
    def get(self, key):
        """Get a value by key"""
        value = self.client.get(key)
        if value:
            return json.loads(value)
        return None
    
    def add_to_set(self, key, *values):
        """Add values to a set"""
        return self.client.sadd(key, *values)
    
    def add_to_sorted_set(self, key, mapping):
        """Add items to sorted set"""
        return self.client.zadd(key, mapping)
    
    def get_leaderboard(self, key, start=0, end=-1):
        """Get sorted set range with scores"""
        return self.client.zrange(key, start, end, withscores=True)</code></pre>
            </div>

            <h3>Memcached</h3>
            <div class="memcached-section">
                <p><strong>Memcached</strong> is a simple, high-performance, distributed memory caching system designed for speeding up dynamic web applications.</p>
                
                <h4>Key Features:</h4>
                <ul>
                    <li><strong>Simple Protocol:</strong> Text-based protocol for easy integration</li>
                    <li><strong>Distributed:</strong> Built-in support for distributed caching</li>
                    <li><strong>High Performance:</strong> Optimized for simple key-value operations</li>
                    <li><strong>Memory Efficient:</strong> Efficient memory usage with slab allocation</li>
                    <li><strong>LRU Eviction:</strong> Built-in LRU eviction policy</li>
                </ul>
            </div>

            <div class="example">
                <h5>Memcached Python Implementation:</h5>
                <pre><code>import memcache
import json

class MemcachedCache:
    def __init__(self, servers=['127.0.0.1:11211']):
        self.client = memcache.Client(servers)
    
    def set(self, key, value, ttl=0):
        """Set a key-value pair with optional TTL"""
        serialized_value = json.dumps(value)
        return self.client.set(key, serialized_value, time=ttl)
    
    def get(self, key):
        """Get a value by key"""
        value = self.client.get(key)
        if value:
            return json.loads(value)
        return None
    
    def get_multi(self, keys):
        """Get multiple values"""
        results = self.client.get_multi(keys)
        return {k: json.loads(v) if v else None for k, v in results.items()}
    
    def set_multi(self, mapping, ttl=0):
        """Set multiple key-value pairs"""
        serialized_mapping = {k: json.dumps(v) for k, v in mapping.items()}
        return self.client.set_multi(serialized_mapping, time=ttl)</code></pre>
            </div>

            <h3>Redis vs Memcached Comparison</h3>
            <table>
                <tr>
                    <th>Feature</th>
                    <th>Redis</th>
                    <th>Memcached</th>
                </tr>
                <tr><td><strong>Data Types</strong></td><td>Rich (strings, lists, sets, etc.)</td><td>Simple (strings only)</td></tr>
                <tr><td><strong>Persistence</strong></td><td>Yes (RDB, AOF)</td><td>No</td></tr>
                <tr><td><strong>Replication</strong></td><td>Yes (master-slave)</td><td>No (client-side)</td></tr>
                <tr><td><strong>Clustering</strong></td><td>Yes (built-in)</td><td>No (client-side)</td></tr>
                <tr><td><strong>Memory Usage</strong></td><td>Higher</td><td>Lower</td></tr>
                <tr><td><strong>Performance</strong></td><td>Excellent</td><td>Excellent</td></tr>
                <tr><td><strong>Use Cases</strong></td><td>Complex applications</td><td>Simple caching</td></tr>
            </table>

            <div class="tip">
                <h4>Choose Redis When:</h4>
                <ul>
                    <li>Need complex data structures beyond simple key-value</li>
                    <li>Need to persist cache data</li>
                    <li>Need messaging capabilities (Pub/Sub)</li>
                    <li>Need transactions or atomic operations</li>
                    <li>Need advanced features like scripting</li>
                </ul>
            </div>

            <div class="tip">
                <h4>Choose Memcached When:</h4>
                <ul>
                    <li>Only need basic key-value caching</li>
                    <li>Need maximum memory efficiency</li>
                    <li>Need simple horizontal scaling</li>
                    <li>Need maximum throughput for simple operations</li>
                    <li>Want simple, straightforward caching</li>
                </ul>
            </div>

            <h2 id="cdn">üåê CDN Caching</h2>
            <p>Content Delivery Network (CDN) caching is a distributed caching strategy that stores content at geographically distributed edge servers to reduce latency and improve user experience.</p>

            <h3>How CDN Caching Works</h3>
            <div class="cdn-section">
                <h4>CDN Workflow:</h4>
                <ol>
                    <li><strong>User Request:</strong> User requests content from application</li>
                    <li><strong>Edge Server:</strong> Request routed to nearest edge server</li>
                    <li><strong>Cache Check:</strong> Edge server checks if content is cached</li>
                    <li><strong>Cache Hit:</strong> If cached, content served directly from edge</li>
                    <li><strong>Cache Miss:</strong> If not cached, content fetched from origin</li>
                    <li><strong>Cache Storage:</strong> Content cached at edge server for future requests</li>
                </ol>
            </div>

            <h3>CDN Cache Configuration</h3>
            <div class="example">
                <h5>Cache Headers:</h5>
                <pre><code># Control caching behavior
Cache-Control: public, max-age=3600, s-maxage=7200
Expires: Wed, 21 Oct 2025 07:28:00 GMT
ETag: "33a64df551425fcc55e4d42a148795d9f25f89d4"
Last-Modified: Wed, 21 Oct 2023 07:28:00 GMT
Vary: Accept-Encoding, Accept-Language</code></pre>
            </div>

            <div class="example">
                <h5>CDN Cache Implementation:</h5>
                <pre><code># Different caching strategies for different content types
CACHE_STRATEGIES = {
    'static_assets': {
        'max_age': 31536000,  # 1 year
        'immutable': True,
        'public': True
    },
    'html_pages': {
        'max_age': 300,  # 5 minutes
        'must_revalidate': True,
        'public': True
    },
    'api_responses': {
        'max_age': 60,  # 1 minute
        'private': True,
        'vary': ['Authorization', 'Accept-Language']
    }
}

def get_cache_headers(content_type):
    """Get appropriate cache headers for content type"""
    strategy = CACHE_STRATEGIES.get(content_type, {})
    
    headers = {}
    
    if strategy.get('public'):
        headers['Cache-Control'] = 'public'
    elif strategy.get('private'):
        headers['Cache-Control'] = 'private'
    
    if strategy.get('max_age'):
        headers['Cache-Control'] += f', max-age={strategy["max_age"]}'
    
    return headers</code></pre>
            </div>

            <h3>CDN Cache Types</h3>
            <table>
                <tr>
                    <th>Type</th>
                    <th>Approach</th>
                    <th>Use Case</th>
                    <th>Advantages</th>
                    <th>Disadvantages</th>
                </tr>
                <tr><td><strong>Push CDN</strong></td><td>Content pushed proactively</td><td>Static content</td><td>Guaranteed cache hits</td><td>Higher storage costs</td></tr>
                <tr><td><strong>Pull CDN</strong></td><td>Content pulled on-demand</td><td>Dynamic content</td><td>Efficient storage</td><td>Initial cache misses</td></tr>
            </table>

            <h2 id="best-practices">üí° Best Practices</h2>

            <h3>Cache Key Design</h3>
            <div class="best-practices">
                <h4>Key Principles:</h4>
                <ul>
                    <li><strong>Consistent Naming:</strong> Use consistent, hierarchical naming conventions</li>
                    <li><strong>Avoid Collisions:</strong> Ensure keys are unique across different data types</li>
                    <li><strong>Include Version:</strong> Include version numbers for cache invalidation</li>
                    <li><strong>Hierarchical Structure:</strong> Use prefixes for logical grouping</li>
                </ul>
            </div>

            <div class="example">
                <h5>Good Cache Key Examples:</h5>
                <pre><code># Good cache key examples
cache_keys = {
    'user_profile': f"user:profile:{user_id}:v1",
    'product_details': f"product:details:{product_id}:v2",
    'search_results': f"search:results:{query_hash}:{page}:v1",
    'session_data': f"session:data:{session_id}:v1"
}</code></pre>
            </div>

            <h3>Cache Monitoring</h3>
            <div class="example">
                <h5>Cache Monitoring Implementation:</h5>
                <pre><code>import time
from functools import wraps

class CacheMonitor:
    def __init__(self):
        self.stats = {
            'hits': 0,
            'misses': 0,
            'errors': 0,
            'total_time': 0,
            'request_count': 0
        }
    
    def record_hit(self, duration):
        self.stats['hits'] += 1
        self.stats['total_time'] += duration
        self.stats['request_count'] += 1
    
    def record_miss(self, duration):
        self.stats['misses'] += 1
        self.stats['total_time'] += duration
        self.stats['request_count'] += 1
    
    def get_hit_rate(self):
        total_requests = self.stats['hits'] + self.stats['misses']
        return self.stats['hits'] / total_requests if total_requests > 0 else 0
    
    def get_average_latency(self):
        return self.stats['total_time'] / self.stats['request_count'] if self.stats['request_count'] > 0 else 0</code></pre>
            </div>

            <h2 id="pitfalls">‚ö†Ô∏è Common Pitfalls</h2>

            <h3>Cache Stampede</h3>
            <div class="warning">
                <p><strong>Problem:</strong> Multiple requests trying to regenerate the same cache entry simultaneously</p>
            </div>

            <div class="example">
                <h5>Cache Stampede Protection:</h5>
                <pre><code>import threading
import time

class CacheStampedeProtection:
    def __init__(self, cache):
        self.cache = cache
        self.locks = {}
        self.lock_creation_lock = threading.Lock()
    
    def get_with_protection(self, key, generate_func, ttl=3600):
        """Get value from cache with stampede protection"""
        # Try to get from cache first
        value = self.cache.get(key)
        if value is not None:
            return value
        
        # Get or create lock for this key
        with self.lock_creation_lock:
            if key not in self.locks:
                self.locks[key] = threading.Lock()
            lock = self.locks[key]
        
        # Try to acquire lock
        if lock.acquire(blocking=False):
            try:
                # Double-check cache after acquiring lock
                value = self.cache.get(key)
                if value is not None:
                    return value
                
                # Generate new value
                value = generate_func()
                self.cache.set(key, value, ttl)
                return value
            finally:
                lock.release()
        else:
            # Wait for other thread to finish
            time.sleep(0.1)
            return self.get_with_protection(key, generate_func, ttl)</code></pre>
            </div>

            <h3>Hot Key Problem</h3>
            <div class="warning">
                <p><strong>Problem:</strong> Single cache key receiving too many requests</p>
            </div>

            <div class="example">
                <h5>Hot Key Mitigation:</h5>
                <pre><code>class HotKeyMitigation:
    def __init__(self, cache):
        self.cache = cache
    
    def get_with_replication(self, key, replica_count=3):
        """Replicate hot keys across multiple cache entries"""
        import random
        
        # Try replicated keys first
        for i in range(replica_count):
            replica_key = f"{key}:replica:{i}"
            value = self.cache.get(replica_key)
            if value is not None:
                return value
        
        # Fallback to original key
        value = self.cache.get(key)
        if value is not None:
            # Replicate to random replica
            replica_index = random.randint(0, replica_count - 1)
            replica_key = f"{key}:replica:{replica_index}"
            self.cache.set(replica_key, value)
        
        return value</code></pre>
            </div>

            <h2 id="summary">üìã Summary</h2>
            <div class="benefits">
                <p>Caching is a fundamental technique in system design that can dramatically improve performance and user experience. Key takeaways include:</p>
                
                <h3>Key Concepts:</h3>
                <ul>
                    <li><strong>Caching Strategies:</strong> Choose between write-through, write-around, and write-back based on requirements</li>
                    <li><strong>Eviction Policies:</strong> Select appropriate policies (LRU, LFU, FIFO) based on access patterns</li>
                    <li><strong>Technology Choice:</strong> Choose between Redis and Memcached based on feature requirements</li>
                    <li><strong>CDN Caching:</strong> Leverage CDN for global content distribution and reduced latency</li>
                </ul>
                
                <h3>Best Practices:</h3>
                <ul>
                    <li><strong>Design for Consistency:</strong> Plan cache invalidation strategies early</li>
                    <li><strong>Monitor Performance:</strong> Track hit rates, latency, and memory usage</li>
                    <li><strong>Handle Edge Cases:</strong> Protect against cache stampede and hot key problems</li>
                    <li><strong>Choose Appropriate TTL:</strong> Balance data freshness with performance</li>
                </ul>
                
                <h3>Common Patterns:</h3>
                <ul>
                    <li><strong>Cache-Aside:</strong> Application manages cache explicitly</li>
                    <li><strong>Cache-Through:</strong> Cache sits between application and database</li>
                    <li><strong>Multi-Level Caching:</strong> Combine different cache layers for optimal performance</li>
                </ul>
            </div>

            <h3>Next Steps</h3>
            <p>After mastering caching concepts, explore:</p>
            <ul>
                <li><strong>Message Queues</strong> for asynchronous processing</li>
                <li><strong>Database optimization</strong> strategies</li>
                <li><strong>Performance monitoring</strong> and observability</li>
                <li><strong>Load balancing</strong> and scaling strategies</li>
            </ul>

            <p style="text-align: center; font-size: 1.2em; color: #3498db; margin-top: 30px;">
                <strong>Understanding caching is crucial for building high-performance systems. Master these concepts to optimize your applications! üöÄ</strong>
            </p>
        </div>
    </div>

    <script>
        function toggleSidebar() {
            const sidebar = document.getElementById('sidebar');
            sidebar.classList.toggle('active');
        }

        // Close sidebar when clicking outside on mobile
        document.addEventListener('click', function(event) {
            const sidebar = document.getElementById('sidebar');
            const toggle = document.querySelector('.sidebar-toggle');
            
            if (window.innerWidth <= 768 && 
                !sidebar.contains(event.target) && 
                !toggle.contains(event.target) && 
                sidebar.classList.contains('active')) {
                sidebar.classList.remove('active');
            }
        });

        // Smooth scrolling for anchor links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    const tocElement = document.querySelector('.toc');
                    const tocHeight = tocElement ? tocElement.offsetHeight : 0;
                    const offset = tocHeight + 40;
                    
                    const targetPosition = target.offsetTop - offset;
                    
                    window.scrollTo({
                        top: targetPosition,
                        behavior: 'smooth'
                    });
                    
                    document.querySelectorAll('.toc a').forEach(link => {
                        link.classList.remove('active');
                    });
                    this.classList.add('active');
                }
            });
        });

        // Highlight current section in TOC on scroll
        window.addEventListener('scroll', function() {
            const sections = document.querySelectorAll('h2[id]');
            const tocLinks = document.querySelectorAll('.toc a');
            
            let current = '';
            const tocElement = document.querySelector('.toc');
            const tocHeight = tocElement ? tocElement.offsetHeight : 0;
            const offset = tocHeight + 50;
            
            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                if (window.scrollY >= sectionTop - offset) {
                    current = section.getAttribute('id');
                }
            });
            
            tocLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === '#' + current) {
                    link.classList.add('active');
                }
            });
        });
    </script>
</body>
</html>